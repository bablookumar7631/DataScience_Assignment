{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44a41438-f6bc-451f-9ca8-62e0c3bf29be",
   "metadata": {},
   "source": [
    "# Boosting-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5ea76-0d71-4998-905d-cf9096df0b5b",
   "metadata": {},
   "source": [
    "### Q1. What is Gradient Boosting Regression?\n",
    "\n",
    "### Ans:-\n",
    "Gradient Boosting Regression is a machine learning technique used for regression problems, which involve predicting a continuous numerical output variable. It is an ensemble learning method that builds a predictive model by combining the predictions of multiple individual models, typically decision trees, to create a more accurate and robust final prediction.\n",
    "\n",
    "**Here's how Gradient Boosting Regression works:**\n",
    "\n",
    "1. Decision Trees as Base Learners: Gradient Boosting Regression uses decision trees as its base learners. Decision trees are simple models that partition the data into subsets based on features and make predictions within each subset.\n",
    "\n",
    "2. Sequential Training: The algorithm works sequentially. It starts with a single decision tree, which is often a very simple one, like a single node or a small tree with limited depth. This initial tree makes predictions on the data.\n",
    "\n",
    "3. Residual Calculation: The algorithm then calculates the difference (residuals) between the actual target values and the predictions made by the initial tree. These residuals represent the errors made by the initial model.\n",
    "\n",
    "4. Building Weak Learners: In the next step, another decision tree is trained to predict these residuals. This new tree is called a \"weak learner\" because it focuses on capturing the errors left by the previous model.\n",
    "\n",
    "5. Boosting: The predictions from this new weak learner are added to the predictions of the previous model, adjusting the overall prediction in an attempt to reduce the errors further. This process is repeated iteratively, with each new weak learner attempting to correct the errors made by the previous ones.\n",
    "\n",
    "6. Combining Predictions: The final prediction is obtained by summing up the predictions from all the weak learners. The learning rate, which is a hyperparameter, controls the contribution of each weak learner to the final prediction.\n",
    "\n",
    "7. Regularization: To prevent overfitting, Gradient Boosting Regression includes regularization techniques like controlling the depth of the individual trees and using a learning rate.\n",
    "\n",
    "Gradient Boosting Regression is known for its high predictive accuracy and is widely used in various regression tasks. Popular libraries like XGBoost, LightGBM, and scikit-learn provide implementations of Gradient Boosting Regression, making it accessible and easy to use for data scientists and machine learning practitioners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a445d-fe1e-439c-ba34-50f5fd1ff4a0",
   "metadata": {},
   "source": [
    "### Q2. Implement a simple gradient boosting algorithm from scratch using Python and NumPy. Use a simple regression problem as an example and train the model on a small dataset. Evaluate the model's performance using metrics such as mean squared error and R-squared.\n",
    "\n",
    "### Ans:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6211430a-f60f-444e-af20-7482472371a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0093\n",
      "R-squared: 0.9802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
      "/tmp/ipykernel_1098/3913969115.py:44: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.sort(5 * np.random.rand(80, 1), axis=0)\n",
    "y = np.sin(X).ravel() + np.random.normal(0, 0.1, X.shape[0])\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    ssr = np.sum((y_true - y_pred) ** 2)\n",
    "    sst = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ssr / sst)\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.estimators = []\n",
    "        self.intercepts = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize the model with the mean of the target variable\n",
    "        initial_prediction = np.mean(y)\n",
    "        self.estimators.append(initial_prediction)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Compute the residuals\n",
    "            residuals = y - self.predict(X)\n",
    "\n",
    "            # Fit a decision tree to the residuals\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residuals)\n",
    "\n",
    "            # Update the model with the new tree\n",
    "            self.estimators.append(tree)\n",
    "            self.intercepts.append(self.learning_rate)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions using all estimators\n",
    "        predictions = np.sum(self.intercepts[i] * estimator.predict(X) for i, estimator in enumerate(self.estimators[1:]))\n",
    "        return predictions + self.estimators[0]\n",
    "\n",
    "# Train the Gradient Boosting model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Calculate and print metrics\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r_squared(y, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d37e0b-3a50-490c-b339-bc9cb092b3bf",
   "metadata": {},
   "source": [
    "### Q3. Experiment with different hyperparameters such as learning rate, number of trees, and tree depth to optimise the performance of the model. Use grid search or random search to find the best hyperparameters.\n",
    "\n",
    "### Ans:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae61ebd-fe71-4fa7-b0ae-941aabc8dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe15e92-b606-405d-9c6b-e992a219dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.sort(5 * np.random.rand(80, 1), axis=0)\n",
    "y = np.sin(X).ravel() + np.random.normal(0, 0.1, X.shape[0])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Create the Gradient Boosting Regressor model\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(f\"Mean Squared Error on Test Set: {mse:.4f}\")\n",
    "print(f\"R-squared on Test Set: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3602a0b6-5438-480d-bd88-ee20c79cdedd",
   "metadata": {},
   "source": [
    "### Q4. What is a weak learner in Gradient Boosting?\n",
    "\n",
    "### Ans:-\n",
    "In the context of Gradient Boosting, a \"weak learner\" refers to a base model or a simple predictive model that is used as the building block for the ensemble. Weak learners are typically models that are only slightly better than random guessing on a given problem. Despite their simplicity and limited predictive power on their own, weak learners can be combined in a clever way to create a strong predictive model through boosting.\n",
    "\n",
    "**Some characteristics of weak learners in Gradient Boosting include:**\n",
    "\n",
    "1. Low Complexity: Weak learners are usually simple models, such as shallow decision trees (stumps) or linear models. These models have limited depth or complexity and may not capture the underlying patterns in the data well.\n",
    "\n",
    "2. Slight Predictive Power: Weak learners typically have an accuracy slightly better than random chance for the problem they are applied to. They might make predictions that are slightly better than random guessing, but they are far from being highly accurate.\n",
    "\n",
    "3. Emphasis on Errors: Weak learners focus on capturing the errors made by previous models in the ensemble. They are trained to correct the mistakes of the existing ensemble members.\n",
    "\n",
    "In the context of Gradient Boosting, a sequence of weak learners is trained sequentially. Each weak learner is trained to predict the residuals (the differences between the actual target values and the current ensemble's predictions) from the previous iterations. By combining these weak learners and their predictions with careful weighting, Gradient Boosting is able to gradually improve its performance and produce a strong predictive model.\n",
    "\n",
    "The strength of Gradient Boosting lies in its ability to effectively combine many weak learners into an ensemble that can make highly accurate predictions. Each weak learner contributes its small part in improving the overall model, and through the boosting process, the ensemble becomes a powerful predictor. This is in contrast to bagging techniques like Random Forest, where each base learner is typically strong and trained independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426104d-0ab8-4d8c-801e-63966c69883c",
   "metadata": {},
   "source": [
    "### Q5. What is the intuition behind the Gradient Boosting algorithm?\n",
    "\n",
    "### Ans:-\n",
    "The intuition behind the Gradient Boosting algorithm can be summarized as follows:\n",
    "\n",
    "1. Sequential Improvement: Gradient Boosting is an ensemble learning technique that aims to improve the performance of a predictive model by sequentially adding simple models (weak learners) to the ensemble. Each weak learner focuses on correcting the errors made by the previous ones.\n",
    "\n",
    "2. Gradient Descent: The name \"Gradient Boosting\" comes from the optimization technique it employs, which is similar to gradient descent. Instead of directly optimizing the model parameters, Gradient Boosting optimizes the residuals (the differences between the actual and predicted values) of the model. It does so by finding the weak learner that best fits the residuals, effectively moving the model in the direction that reduces the errors.\n",
    "\n",
    "3. Combining Weak Models: Weak learners, such as shallow decision trees or linear models, are used as building blocks. These models are individually not very powerful, but they are carefully combined to form a strong ensemble. Each weak learner is assigned a weight in the final prediction, with more accurate models having higher weights.\n",
    "\n",
    "4. Boosting: The term \"boosting\" refers to the iterative process of training and adding weak learners to the ensemble. At each step, a new weak learner is trained to predict the residuals of the current ensemble. This new learner's predictions are then added to the ensemble, adjusting the model's predictions and reducing the residuals.\n",
    "\n",
    "5. Weighted Voting: In Gradient Boosting, predictions from weak learners are not equally weighted. Each weak learner's contribution is scaled by a learning rate, which is a hyperparameter. This learning rate controls how much each new learner's prediction influences the final ensemble prediction. Smaller learning rates make the learning process more gradual.\n",
    "\n",
    "6. Regression or Classification: Gradient Boosting can be applied to both regression and classification problems. For regression, it minimizes the mean squared error of predictions, while for classification, it minimizes deviance or exponential loss.\n",
    "\n",
    "In essence, the intuition behind Gradient Boosting is to iteratively build an ensemble of weak models that collectively improve their performance by focusing on the mistakes made by previous models. This sequential, error-correcting process leads to a strong predictive model that can generalize well to unseen data. Gradient Boosting has proven to be a powerful and versatile technique in machine learning, and it has been used successfully in various domains and competitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15651572-4bd3-4d22-bcf2-0045835a289b",
   "metadata": {},
   "source": [
    "### Q6. How does Gradient Boosting algorithm build an ensemble of weak learners?\n",
    "\n",
    "### Ans:-\n",
    "The Gradient Boosting algorithm builds an ensemble of weak learners sequentially, with each weak learner added to the ensemble in a way that corrects the errors made by the previous models. Here's how the process works:\n",
    "\n",
    "1. Initialization: Gradient Boosting starts with an initial prediction, which is often a simple estimate like the mean of the target values for regression problems or the log-odds for binary classification problems.\n",
    "\n",
    "2. Iterative Process:\n",
    "\n",
    "- Step 1: Calculate Residuals - The algorithm calculates the difference (residuals) between the actual target values and the current predictions of the ensemble. These residuals represent the errors made by the current ensemble.\n",
    "\n",
    "- Step 2: Train a Weak Learner - A new weak learner (e.g., a decision tree or linear model) is trained to predict the residuals. The goal is to find a model that fits the residuals as well as possible.\n",
    "\n",
    "- Step 3: Update Ensemble - The predictions of the new weak learner are added to the predictions of the current ensemble. This update is weighted by a hyperparameter called the learning rate, which controls the contribution of the new learner. The learning rate is a small positive number (e.g., 0.1).\n",
    "\n",
    "- Step 4: Update Residuals - The residuals are updated by subtracting the predictions made by the new learner. This step adjusts the residuals to focus on the errors that were not corrected by the previous models.\n",
    "\n",
    "- Step 5: Repeat - Steps 1 to 4 are repeated for a specified number of iterations or until a convergence criterion is met.\n",
    "\n",
    "3. Final Prediction: The final prediction for a new input is obtained by summing up the predictions made by all the weak learners in the ensemble. Each weak learner's prediction is scaled by its corresponding learning rate.\n",
    "\n",
    "The key idea behind this process is that each new weak learner is specialized in correcting the errors that the previous ensemble made on the training data. By iteratively focusing on these errors, the Gradient Boosting algorithm gradually improves the accuracy of the model. The learning rate controls how much each new learner contributes to the final prediction, allowing for gradual adjustments and preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adccfb6-8ae0-47ed-9fca-d3a331454bdc",
   "metadata": {},
   "source": [
    "### Q7. What are the steps involved in constructing the mathematical intuition of Gradient Boosting algorithm?\n",
    "\n",
    "### Ans:-\n",
    "Constructing the mathematical intuition behind the Gradient Boosting algorithm involves breaking down the algorithm into its key mathematical components and understanding how they work together to improve predictive performance. Here are the steps involved in constructing the mathematical intuition of the Gradient Boosting algorithm:\n",
    "\n",
    "1. Initial Prediction and Residuals:\n",
    "\n",
    "- Start with an initial prediction, often a simple estimate like the mean of the target values (for regression) or the log-odds (for classification).\n",
    "- Calculate the residuals by subtracting the initial predictions from the actual target values. The residuals represent the errors made by the initial model.\n",
    "\n",
    "2. Weak Learner Training:\n",
    "\n",
    "- Train a weak learner (base model) on the dataset, with the goal of capturing the patterns and relationships in the data that the current ensemble fails to capture.\n",
    "- For regression problems, the weak learner aims to predict the residuals.\n",
    "- For classification problems, the weak learner aims to predict the negative gradient of the loss function (negative gradient boosting).\n",
    "\n",
    "3. Update the Ensemble:\n",
    "\n",
    "- Combine the predictions of the weak learner with the current ensemble's predictions. Each new prediction is weighted by a learning rate (typically a small positive value) and added to the ensemble's predictions.\n",
    "- The learning rate controls the contribution of the new learner. Smaller learning rates make the learning process more gradual.\n",
    "\n",
    "4. Update Residuals:\n",
    "\n",
    "- Update the residuals by subtracting the predictions made by the new weak learner. This step adjusts the residuals to focus on the errors that were not corrected by the previous models.\n",
    "\n",
    "5. Iteration:\n",
    "\n",
    "- Repeat steps 2 to 4 for a specified number of iterations or until a convergence criterion is met. Each iteration adds a new weak learner and refines the ensemble's predictions.\n",
    "\n",
    "6. Final Prediction:\n",
    "\n",
    "- The final prediction for a new input is obtained by summing up the predictions made by all the weak learners in the ensemble. Each weak learner's prediction is scaled by its corresponding learning rate.\n",
    "\n",
    "7. Loss Function and Gradient:\n",
    "\n",
    "- Gradient Boosting minimizes a specific loss function (e.g., mean squared error for regression or log loss for classification).\n",
    "- The gradient of the loss function with respect to the current ensemble's predictions is used to guide the training of each new weak learner.\n",
    "\n",
    "8. Regularization:\n",
    "\n",
    "- Gradient Boosting often includes regularization techniques to prevent overfitting. Common forms of regularization include limiting the depth of the weak learners (e.g., maximum depth of decision trees) and adjusting the learning rate.\n",
    "\n",
    "9. Early Stopping:\n",
    "\n",
    "- In practice, it's common to employ early stopping to determine the optimal number of iterations. Early stopping monitors the performance on a validation dataset and stops adding weak learners when performance starts to degrade.\n",
    "\n",
    "10. Hyperparameter Tuning:\n",
    "\n",
    "- Fine-tuning hyperparameters such as the number of weak learners, learning rate, and maximum depth of the weak learners can significantly impact the model's performance.\n",
    "\n",
    "By understanding these mathematical components and their interactions, you can gain a deeper intuition of how Gradient Boosting works to build a strong predictive model by iteratively correcting errors and minimizing a specified loss function. The algorithm's strength lies in its ability to gradually improve its predictions by focusing on the mistakes made by the current ensemble."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
